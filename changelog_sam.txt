


Delete all things related to calibration. That means that I could really simplify the mgf_select_reporter file, but I won't.

A recommendation to dad: Make a directory for every project, and then make a subdirectory for TestMGFfiles.

I could also make these scripts executable from anywhere, which would probably make it easier. And I'd put some text files inside of that directory for the inverse matrices, so it could find itself.


It was printing out type + number! That means it'll be fine, as long as we label correctly.

Added TMT10-inv.txt file

Added reporters list in mgf_select_reporter.pl

Added TMT10 option for python script input.


I'm going to change it so that you can put the script in a folder with the inverse matrices and a few other things, and then run the stuff just from the data folder. 


TO DO: I JUST MOVED EVERYTHING TO A FOLDER CALLED ISOBARIC_EXECUTABLES, NOW I NEED TO ADD THAT TO THE PATH.	

I should write a serializeElement function, that serializes every input in an element.
That wouldn't be too hard.





Now, I need to make it so it writes them to separate files.



TEST: for TMT0, run and see if the index stops, because it's from 126 to 126.

Check TMT10 inverse matrix, because sometimes dads make mistakes.

Added TMT2 and TMT0.

NEED TO CHANGE iTRAQ4-inv.txt so there are tabs instead of spaces. IMPORTANT!

Sometimes, there are multiple runs with the same scan number, but they refer to different charges usually.
I want to only keep the one of these that has the lowest error. (the most negative log(e)).

How do I do this? I need to read in each line from the program. Then, I could scan through and keep a log of the duplicates, by keeping track of seen and seen-again. Then, I could go through and find for each duplicate what the smallest E was. Then, finally, I could re-write the file so that only the smallest E was there. The only thing I'd need to make sure of is that if there are two that are EXCATLY the same, I pick the first or something. 


Next thing I should do is maybe make it not do the mgs_select function if there's something already there with the right name.

Also, I could maybe speed up my drop_duplicates function if I gave it the set of things it'll eventually care about.
Then I wouldn't have to fully double up the data.


We only really want aklsjdf.mgf and asldkfj.mgf.txt. mgf_select should put all of the .mgf  into one folder and all the .mgf.txt into another.
F
Maybe just use merged-selected. 

It's very possible that somebody will want the output to save somewhere very far from the input files.

Make another modification file column that it says iTRAQ instead of 144.10207. Also maybe add m+h, delta, z, log(I), and zeta columns.

Figure out how he writes the unacceptable column.


####################################################################################################

IMPORTANT

For this to work, we need to be sure it has the directory structure that I specified.
That's a folder ("TestiTRAQ8mgffiles" for example) containing the raw mgf files. If selected
already, it will have been selected by certain criteria, namely mz_error, type (of reporter ion),
min_intensity, and min_reporters. Running mgf_select_reporter.pl with that criteria will generate a
folder with a certain name, for example "selected-d20-iTRAQ8-1000-2". If you ran it with the new
mgf_select_reporter.pl, inside of this folder should be two more, called "mgf-files" and 
"mgf-txt-files", the former containing the filtered raw mgf files, and the latter containing the
table-like files generated by mgf_select_reporter.pl. Here's a sample directory structure.

	iTRAQ8mgfFiles
	----selected-d20-iTRAQ8-1000-2
	--------mgf-files
	------------VLS5202.raw.mgf
	------------VLS5218.raw.mgf
	------------VLS5221.raw.mgf
	--------mgf-txt-files
	------------VLS5202.raw.mgf.txt
	------------VLS5218.raw.mgf.txt
	------------VLS5221.raw.mgf.txt
	--------VLS5202.raw.mgf
	--------VLS5218.raw.mgf
	--------VLS5221.raw.mgf


####################################################################################################

NOTES ON mgf_select_reporter:

It doesn't actually make a hash table, what it does is make two parallel arrays. Points increments,
one for each sample within a scan. mz[0] is the m/z of the first row in a scan. intensity[0] is the
intensity of that row.

Once it's done the scan,


He sort of did it in an odd way. There's a bunch of if statements, and then he finally has an if else, on reading a data line.

So, it'll go through the whole thing a lot, and keep all the data in two parallel arrays. And then when it's
done with that, it iterates through the reporter ions. For each one, it checks against every data point, sees if the data point's mass is within the mz_error tolerance, and if it is, adds it to a sum variable. And also makes note of if the reporter ion is found.

The two sum variables confuse me a little bit. I think I need to write a little perl script for experimentation purposes, that has both variables and sees what happens when I try and access them. That could be some of the funkiness. 

Anyway, if it works the way he wrote it, it'll sum up the masses per ion, and every time you have a working one,
it'll check if you're above the threshold for min_intensity. Once you are, it'll say that that one is found.

I just ran a test file, and it looks like running it with 1000 2 gives me 13,549 KB for QE00636-1.mgf and 
18,738 kb for QE00675-2.mgf. The second time through, it was actually different. I don't really know why. Instead it was 9,730 and 15,701 respectively.

I was being a fool before, it does make a difference. The min_intensity is used to calculate the amount needed to 
trigger reporter_found. 



NOTES:
Should take protein, and look at RAT_75 or HUMAN... or MOUSE... and find the associated gene name, and the associated gene_id, and store them respectively.
Also, in multiple places. There's also other protein, and other gene name, and other gene_id


Order of business:
It's been a while. First, I need to remember how it worked in the first place. That means I needto run the script.
Then, I need to figure out how to make the changes. It looks like I'm going to just be adding in a column for charge, and a column for charge state. And that should be enough for the first part.

Adding charge to the written table: DONE


FIRST QUESTION: Where are there repeats? Are the repeats in spectrum? Are they in scans?
Repeats only matter within a single file.

It looks like some files have A LOT of repeated ones.
It also looks like scans sometimes repeats with 2+ and 3+, but spectrum never does.
They've got the exact same data though, it's just that they change the charge number.
So, I've got to keep track of the charge number! Also, filename.


We're getting multi-index errrors, so I'm adding charge to the pandas index, so that its unique again. One problem now is that there's no charge thing for the xml file, so it may have trouble. I think
that it should be okay, if it duplicates the xml stuff for each entry that matches.

What I want is for the info to be merged on to all matching objects, sort of like a SQL join table.
Done! What a great thing computer science knowledge is.

Comprehensive list of sample data with duplicates:
DATA_TMTzerotest : NONE
DATA_TMT10test: LOTS!
DATA_TMT6test: NONE
DATA_TestTMT2: LOTS!
DATA_TMT6test: NONE
DATA_iTRAQ8test: NONE
DATA_iTRAQ4test: LOTS!

If there are two things with same scan, same charge, different log(e), then we want to give a ranking to both so that we don't discard, but we know which was better.

We want to make a note in each if there was a duplicate scan number in the same file.

Make a checkbox that asks whether you'd like to merge them at the end as well.
Make everything directory-agnostic.

I also want to switch things to join from appending '/', because that's not very directory agnostic.


Future change: I may want to increase parsing speed by getting rid of all double .* instances in a file. Also, I should precompile the regexes. That's probably a big thing. I should profile that.

The regex is SO slow. That's crazy. Once you get to the points, you know you can skip everything else, until you're out of the points. But it doesn't do that, it matches every single regex over and over, and makes them as well instead of using precompiled ones.

It's weird, it looks like out_cal only adjusts the mz of things to make them better, but doesn't change how the reporter-ion intensities are written. No out_cal_table. Does he want one? I think so.


So, to sumarrize what I need to do:
First, do the normal thing. But keep track of each and every peak, and where it happened, per run. Then, at the end of the run, you see how far off the highest peak is, you scale where the reporter ions should be, then you re-run selection, writing the table with amounts from the scaling and thinning of error threshold. And if the thing passes the test the second time, then you know it's okay.

So, you run the thing, but instead of writing anything, you instead use the values to create a new mass array, and re-run it with that. But you've got to do that for every single run, not for the whole thing.

1) Do the selection process on a single run
2) Find the maximum peak
3) Scale the values so that they match that one perfectly.
4) Use those values to do the selection again
5) If it matches the criteria, write the values, and the table.

I think maybe I should have a totally separate perl script if you're reselecting, it's a big difference.

I should put a check to make sure that the threshold value isn't so big that there's overlap, because overlap is really bad. It means that when you scale, there might be ambiguity in which one you scale in relation to. Things should only go in one pocket!

Note that the min_intensity and min_reporters no longer applies to the first selection process if you're recalibrating, which means that we don't need the extra variables recal_min_intensity and recal_min_reporters.


What should I do in the next train? I need to put in reasonable defaults. I also need to adjust the names so that they're understandable. But, more importantly, I need to have the python script route correctly. That shouldn't be a frontend thing, the frontend should just pass everything down.



I need to test out four different things.
First: should_select and recalibrate
Second: not should_select and recalibrate
Third: should_select and not_recalibrate
Fourth: not should_select and not_recalibrate

Forsome reason if I recalibrate then it makes the tsxt but if I don't it doesn't. Maybe SI need to change that one

That's nice, it looks like recalibrating doesn't include THREE that not recalibrating does. That sounds like it's working to me.
What if I change my range to be even smaller? Two?
Also good is that selecting doesn't change the mgf_txt files

Thinning it out actually doesn't make much difference, looks like dad has a nice instrument on his hands. Thinning to one makes a little bit more difference. And, as expected, zero makes it write nothing.

Pretty validating, the recalibration makes a lot more of the runs match. How did I test it? I did a match with width 1, then I did a match with first width 20 and recal 1, and there were about twice as many caught with the second way than with the first

So, I think that those two things are good. The next part I need to get working is the parse_xml. I remember talking about this. Sometimes you want to select the MGF 
so that you can do a gpm search. And sometimes you want to combine the MGF and the xml file. But you never really want to just parse the XML file, that's not so useful.

So sometimes you can give it a mgf.txt directory and a xml file and have it do the rest, and sometime you give it a mgf directory and an xml file and it'll parse the mgfs, and then combine everything. So, have a second tab where there's a file that gives

Parse xml file:
Option: use pre-extracted reporter ion mgf.txt files OR select from mgf file first.
Options for pre-extract: All of the things you need for extraction.

Once it's selected, I'll have a directory for the .mgf.txt files. Now, I need to run parse_xtandem_sam. 

It'll be easiest to just start over.

I could get a lot of milage using out of the fact that the mgf data is sorted by intensity.


Looks like doing server-side regex is a bad idea, because it only gets it before the new input.

The error it returns when there's already a directory is crazily unhelpful


Make a better doc explaining everything
